# 小组信息

- 组员信息：陈永乐，林金雄

- 组员分工：

- 指导老师：彭伟龙

# 作业题目和内容

## **题目**

用C++实现k-means聚类算法，

## 实验内容

1. 对实验二中的z-score归一化的成绩数据进行测试，观察聚类为2类，3类，4类，5类的结果，观察得出什么结论？
2. 由老师给出测试数据，进行测试，并画出可视化出散点图，类中心，类半径，并分析聚为几类合适。

样例数据(x,y)数据对：



| 3.45 | 7.08 |
| ---- | ---- |
| 1.76 | 7.24 |
| 4.29 | 9.55 |
| 3.35 | 6.65 |
| 3.17 | 6.41 |
| 3.68 | 5.99 |
| 2.11 | 4.08 |
| 2.58 | 7.10 |
| 3.45 | 7.88 |
| 6.17 | 5.40 |
| 4.20 | 6.46 |
| 5.87 | 3.87 |
| 5.47 | 2.21 |
| 5.97 | 3.62 |
| 6.24 | 3.06 |
| 6.89 | 2.41 |
| 5.38 | 2.32 |
| 5.13 | 2.73 |
| 7.26 | 4.19 |
| 6.32 | 3.62 |

找到聚类中心后，判断(2,6)是属于哪一类？

#### **注意**

除文件读取外，不能使用C++基础库以外的API和库函数。

## 作业环境

1、Visual Studio

2、PYcharm 

## 文件说明

第一问的源代码：kmeans.cpp

输入的文件是上一个实验中的文件：z-score_Data.csv

进行聚类算法之后输出的文件：output.csv

第二问的源代码是：visualization2.py

将第二问涉及到的表格转换成.txt文件：test.txt

kmeans聚类散点图：kmeans_TEST.jpg



## 函数说明

```c++
ClusterMethod a;
	a.GetClusterd(v, data, 5, 106, 11);
	//输出
	for (int i = 0; i < v.size(); ++i)
	{
		cout << "第" << i + 1 << "类" << endl;
		for (int j = 0; j < v[i].size(); ++j)
		{
			for (int k = 0; k < v[i][j].size(); ++k)
			{
				cout << v[i][j][k] << " ";
			}
			cout << endl;
		}
	}
```

定义一个用于聚类算法的类：ClusterMethod

调用外部接口函数,输入的参数的含义分别是：聚类数4，样本数106，每个样本的特征数11

使用for循环进行分类的聚类输出。

```python
def center(centers):
    sum = [0, 0]
    for i in centers:  # 计算加和
        sum[0] += i[0]
        sum[1] += i[1]
    # 求所有聚类中心的平均值得到类中心
    avg = [0, 0]
    avg[0] = sum[0] / len(centers)  # 计算平均值
    avg[1] = sum[1] / len(centers)  # 计算平均值
    area = 3.14 * 20  # 设定点的大小
    # 设置图像标题
    print(avg[1])
    plt.title('1特征聚类中心平均值%s，2特征聚类中心平均值%s' % (float('%.3f' % avg[0]), float('%.3f' % avg[1])))
    # 画类中心点
    plt.scatter(avg[0], avg[1], s=area, c=2)  # 画点
    plt.savefig("kmeans_centers.jpg")  # 保存图片
    plt.show()  # 显示图片
    return avg
```

对数据进行kmeans聚类,并可视化散点图，并返回聚类中心

```python
def center(centers):
    sum = [0, 0]
    for i in centers:  # 计算加和
        sum[0] += i[0]
        sum[1] += i[1]
    # 求所有聚类中心的平均值得到类中心
    avg = [0, 0]
    avg[0] = sum[0] / len(centers)  # 计算平均值
    avg[1] = sum[1] / len(centers)  # 计算平均值
    area = 3.14 * 20  # 设定点的大小
    # 设置图像标题
    print(avg[1])
    plt.title('1特征聚类中心平均值%s，2特征聚类中心平均值%s' % (float('%.3f' % avg[0]), float('%.3f' % avg[1])))
    # 画类中心点
    plt.scatter(avg[0], avg[1], s=area, c=2)  # 画点
    plt.savefig("kmeans_centers.jpg")  # 保存图片
    plt.show()  # 显示图片
    return avg
```

代码中的相关数据已经进行相应的注释，这个算法主要是计算两个特征聚类中心的平均值，并进行画图。

```python
def judge(centers):
   
    distance = {}  # 使用字典存储距离信息
    for i in range(n):
        dis = math.sqrt((2 - centers[i][0]) ** 2 + (6 - centers[i][1]) ** 2)
        x = {i: dis}
        distance.update(x)  # 更新字典
    # 输出按照值排序后的字典对应的键值
    print("点(2,6)属于第%d类" % (sorted(distance.items(), key=lambda kv: (kv[1], kv[0]))[0][0] + 1))
```

 判断(2,6)是属于哪一类，即计算点(2,6)到所有聚类中心的欧氏距离

## 实验中设计的技术

使用C++实现第一问主要设计到kmeans的聚类的相关技术，第二问是使用python，主要原因是python有画图工具，而Visual Studio画图麻烦复杂。第二问是在第一问的基础上进行编写代码，最后进行画图。

## 总结

在进行第二问的实验中：

 经过分析，我认为，聚为2类比较合适，因为样本中存在几个比较离散的数据，反映在坐标图上分布的比较偏，在聚类数为2的时候，两个簇中的点的数量比较接近，且划分的比较开，而随着聚类数上升，由于偏远点的存在，始终难以促进每个类簇的点数量接近，只有当聚类数达到比较接近样本点数的时候才能将每个类簇分的比较均匀比较开，但是那样的话"聚"的效果则无法显现了





